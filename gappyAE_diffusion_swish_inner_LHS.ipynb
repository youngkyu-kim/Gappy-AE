{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import IndexLocator\n",
    "import time, sys\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import qmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS_seed=0\n",
    "\n",
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "tf = 1.0\n",
    "dt = 2.0e-3\n",
    "nt = int(tf/dt)\n",
    "xmin = 0; xmax = 1\n",
    "ymin = 0; ymax = 1\n",
    "dims = (ny,nx)\n",
    "\n",
    "# latent space dim.\n",
    "f_list=np.array([3,4,5,6])\n",
    "print('Latent Sapce Dim. {}'.format(f_list))\n",
    "\n",
    "# parameters\n",
    "p_inter=5\n",
    "FOM_parameters = np.arange(75,125+1,1,dtype=int)\n",
    "print(\"Prediction Parameters: {}\".format(FOM_parameters))\n",
    "print(\"training parameters={}\".format(FOM_parameters[p_inter:-p_inter:p_inter]))\n",
    "\n",
    "# generate mesh grid\n",
    "[xv,yv]=np.meshgrid(np.linspace(xmin,xmax,nx),np.linspace(ymin,ymax,ny),indexing='xy')\n",
    "x=xv.flatten()\n",
    "y=yv.flatten()\n",
    "\n",
    "# file path\n",
    "file_path_gappy_LHS_result = \"./diffusion_result/ex16_AE_swish_gappy_inner_LHS_seed_{}_result_seed_{}.p\".format(LHS_seed,seed)\n",
    "print(file_path_gappy_LHS_result)\n",
    "\n",
    "# Gauss-Newton params\n",
    "maxitr=4\n",
    "tol=1e-8\n",
    "\n",
    "# full, inner, bc index\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "x0_multi_index=(multi_index_j[:,0].flatten(),multi_index_i[:,0].flatten())\n",
    "x1_multi_index=(multi_index_j[:,-1].flatten(),multi_index_i[:,-1].flatten())\n",
    "y0_multi_index=(multi_index_j[0,:].flatten(),multi_index_i[0,:].flatten())\n",
    "y1_multi_index=(multi_index_j[-1,:].flatten(),multi_index_i[-1,:].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "x0_raveled_indicies=np.ravel_multi_index(x0_multi_index,dims)\n",
    "x1_raveled_indicies=np.ravel_multi_index(x1_multi_index,dims)\n",
    "y0_raveled_indicies=np.ravel_multi_index(y0_multi_index,dims)\n",
    "y1_raveled_indicies=np.ravel_multi_index(y1_multi_index,dims)\n",
    "bc_raveled_indicies=np.unique(np.concatenate((x0_raveled_indicies,x1_raveled_indicies,\n",
    "                                              y0_raveled_indicies,y1_raveled_indicies)))\n",
    "inner_raveled_indicies=np.setdiff1d(full_raveled_indicies,bc_raveled_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LHS\n",
    "num_msmt = 12\n",
    "sampler = qmc.LatinHypercube(d=2,seed=LHS_seed)\n",
    "sample=sampler.integers(l_bounds=[1, 1], u_bounds=[ny-1,nx-1], n=num_msmt, endpoint=False)\n",
    "msmt_idx=np.sort(np.ravel_multi_index((sample[:,0],sample[:,1]),dims))\n",
    "\n",
    "num_msmt=len(msmt_idx)\n",
    "print(\"# of measurments: {}\".format(num_msmt))\n",
    "print(msmt_idx)\n",
    "\n",
    "# plot measuremnt positions\n",
    "plt.figure()\n",
    "plt.scatter(x[msmt_idx],y[msmt_idx], color = 'blue')\n",
    "plt.axis('square')\n",
    "plt.axis([xmin,xmax,ymin,ymax])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.savefig(\"./diffusion_result/ex16_AE_swish_inner_LHS_seed_{}_{}_samples_seed_{}.png\".format(LHS_seed,num_msmt,seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gappyAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solution=np.zeros((len(f_list),len(FOM_parameters),nt+1,nx*ny))\n",
    "reduced=np.zeros((len(f_list),len(FOM_parameters),nt+1,f_list[-1]))\n",
    "avg_rel_err=np.zeros((len(f_list),len(FOM_parameters)))\n",
    "rel_err=np.zeros((len(f_list),len(FOM_parameters),nt+1))\n",
    "elapsed_time=np.zeros((len(f_list),len(FOM_parameters)))\n",
    "\n",
    "for ii in range(len(f_list)):\n",
    "    f=f_list[ii]\n",
    "    print(\"Dim. of latent space is {}\".format(f))\n",
    "    \n",
    "    # file path\n",
    "    file_name_AE=\"./diffusion_model/ex16_AE_{}_swish_seed_{}.p\".format(f,seed)\n",
    "\n",
    "    # LHS\n",
    "    num_msmt = 12\n",
    "    sampler = qmc.LatinHypercube(d=2,seed=LHS_seed)\n",
    "    sample=sampler.integers(l_bounds=[1, 1], u_bounds=[ny-1,nx-1], n=num_msmt, endpoint=False)\n",
    "    msmt_idx=np.sort(np.ravel_multi_index((sample[:,0],sample[:,1]),dims))\n",
    "\n",
    "    num_msmt=len(msmt_idx)\n",
    "    print(\"# of measurments: {}\".format(num_msmt))\n",
    "    print(msmt_idx)\n",
    "\n",
    "    # plot measuremnt positions\n",
    "    plt.figure()\n",
    "    plt.scatter(x[msmt_idx],y[msmt_idx], color = 'blue')\n",
    "    plt.axis('square')\n",
    "    plt.axis([xmin,xmax,ymin,ymax])\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "    \n",
    "    with open(file=file_name_AE, mode='rb') as ff:    \n",
    "        AE = pickle.load(ff)\n",
    "\n",
    "    en_wu1=AE['en_wu1']\n",
    "    en_bu1=AE['en_bu1']\n",
    "    en_wu2=AE['en_wu2']\n",
    "    de_wu1=AE['de_wu1']\n",
    "    de_bu1=AE['de_bu1']\n",
    "    de_wu2=AE['de_wu2']\n",
    "    de_wu1T=AE['de_wu1T']\n",
    "    de_wu2T=AE['de_wu2T']\n",
    "    de_wu2_sp=AE['de_wu2_sp']\n",
    "    de_wu2T_sp=AE['de_wu2T_sp']\n",
    "    u_ref=AE['u_ref']\n",
    "\n",
    "    latent_dim=de_wu1.shape[1]\n",
    "\n",
    "    # numpy version of AE\n",
    "    def sigmoid_np(input):\n",
    "        return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "    def encoder_u_np_forward(x):\n",
    "        z1 = en_wu1.dot(x) + en_bu1\n",
    "        a1 = z1 * sigmoid_np(z1)\n",
    "        y = en_wu2.dot(a1)   \n",
    "        return y\n",
    "\n",
    "    def decoder_u_np_forward(x):\n",
    "        z1 = de_wu1.dot(x) + de_bu1\n",
    "        a1 = z1 * sigmoid_np(z1)\n",
    "        y = de_wu2.dot(a1)  \n",
    "        return y\n",
    "\n",
    "    def decoder_u_sp_forward(x):\n",
    "        z1 = de_wu1.dot(x) + de_bu1\n",
    "        a1 = z1 * sigmoid_np(z1)\n",
    "        y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "        return y\n",
    "\n",
    "    def decoder_u_np_forward_backwardT(x):\n",
    "        z1 = de_wu1.dot(x) + de_bu1\n",
    "        sigma = sigmoid_np(z1)\n",
    "        a1 = z1 * sigma\n",
    "        y = de_wu2.dot(a1)\n",
    "\n",
    "        dout = de_wu1T\n",
    "        dout = (sigma+a1*(1-sigma))*dout\n",
    "        dydxT = dout.dot(de_wu2T)   \n",
    "        return y,dydxT\n",
    "\n",
    "    def decoder_u_sp_forward_backwardT(x):\n",
    "        z1 = de_wu1.dot(x) + de_bu1\n",
    "        sigma = sigmoid_np(z1)\n",
    "        a1 = z1 * sigma\n",
    "        y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "        dout = de_wu1T\n",
    "        dout = (sigma+a1*(1-sigma))*dout\n",
    "        dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "        return y,dydxT\n",
    "\n",
    "\n",
    "    m,M2=de_wu2.shape\n",
    "\n",
    "    class Decoder_U_FC(nn.Module):\n",
    "\n",
    "        def __init__(self,):\n",
    "            super(Decoder_U_FC, self).__init__()\n",
    "            self.fc1 = nn.Linear(latent_dim,M2)\n",
    "            self.fc1.weight = nn.Parameter(torch.ones(de_wu1.shape))\n",
    "            self.fc1.bias = nn.Parameter(torch.ones(de_bu1.shape))\n",
    "    #         self.fc1.weight = nn.Parameter(torch.tensor(de_wu1))\n",
    "    #         self.fc1.bias = nn.Parameter(torch.tensor(de_bu1))\n",
    "\n",
    "            self.fc2 = nn.Linear(M2,m,bias=False)\n",
    "            self.fc2.weight = nn.Parameter(torch.ones(de_wu2.shape))\n",
    "    #         self.fc2.weight = nn.Parameter(torch.tensor(de_wu2))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model = Decoder_U_FC()\n",
    "\n",
    "    x_in=torch.ones(latent_dim)\n",
    "    y_out=model(x_in)\n",
    "\n",
    "    p_hr=msmt_idx\n",
    "\n",
    "    upstream=torch.zeros_like(y_out)\n",
    "    upstream[p_hr]=1.0\n",
    "\n",
    "    y_out.backward(upstream)\n",
    "\n",
    "    # masks for subnet\n",
    "    wu1_mask=model.fc1.weight.grad\n",
    "    wu2_mask=model.fc2.weight.grad\n",
    "\n",
    "    bu1_mask=model.fc1.bias.grad\n",
    "\n",
    "    # subnet sparse weight\n",
    "    idx1=wu1_mask.to_sparse()._indices()\n",
    "    i1=idx1.numpy()[0]\n",
    "    j1=idx1.numpy()[1]\n",
    "    v1=de_wu1[i1,j1]\n",
    "    wu1_sb_sp=sp.csr_matrix(sp.csr_matrix((v1,(i1,j1)),shape=wu1_mask.shape).toarray())\n",
    "\n",
    "    idx2=wu2_mask.to_sparse()._indices()\n",
    "    i2=idx2.numpy()[0]\n",
    "    j2=idx2.numpy()[1]\n",
    "    v2=de_wu2[i2,j2]\n",
    "    wu2_sb_sp=sp.csr_matrix(sp.csr_matrix((v2,(i2,j2)),shape=wu2_mask.shape).toarray())\n",
    "\n",
    "    # subnet compressed weight\n",
    "    i1,j1,v1=sp.find(wu1_sb_sp)\n",
    "    i1_unique,i1_inverse=np.unique(i1,return_inverse=True)\n",
    "    i1_comp=np.arange(i1_unique.size)\n",
    "    i1_comp=i1_comp[i1_inverse]\n",
    "    j1_unique,j1_inverse=np.unique(j1,return_inverse=True)\n",
    "    j1_comp=np.arange(j1_unique.size)\n",
    "    j1_comp=j1_comp[j1_inverse]\n",
    "    wu1_sb_comp_sp=sp.csr_matrix((v1,(i1_comp,j1_comp)),shape=(i1_unique.size,j1_unique.size))\n",
    "\n",
    "    i2,j2,v2=sp.find(wu2_sb_sp)\n",
    "    i2_unique,i2_inverse=np.unique(i2,return_inverse=True)\n",
    "    i2_comp=np.arange(i2_unique.size)\n",
    "    i2_comp=i2_comp[i2_inverse]\n",
    "    j2_unique,j2_inverse=np.unique(j2,return_inverse=True)\n",
    "    j2_comp=np.arange(j2_unique.size)\n",
    "    j2_comp=j2_comp[j2_inverse]\n",
    "    wu2_sb_comp_sp=sp.csr_matrix((v2,(i2_comp,j2_comp)),shape=(i2_unique.size,j2_unique.size))\n",
    "\n",
    "    wu1_sb_comp_dense=wu1_sb_comp_sp.toarray()\n",
    "    wu1_sb_comp_dense=wu1_sb_comp_dense[j2_unique]\n",
    "    wu2_sb_comp_dense=wu2_sb_comp_sp.toarray()\n",
    "\n",
    "    wu1_sb_comp_denseT=wu1_sb_comp_dense.T\n",
    "    wu2_sb_comp_denseT=wu2_sb_comp_dense.T\n",
    "\n",
    "    # subnet compressed bias\n",
    "    bu1_sb_comp_dense=de_bu1[i1_unique]\n",
    "    bu1_sb_comp_dense=bu1_sb_comp_dense[j2_unique]\n",
    "\n",
    "    # Using sparse matrix\n",
    "    wu2_sb_comp_sp=sp.csr_matrix(wu2_sb_comp_dense,dtype='float32')\n",
    "    wu2_sb_comp_spT=sp.csr_matrix(wu2_sb_comp_denseT,dtype='float32')\n",
    "\n",
    "    def decoder_u_sb_np_forward(x):\n",
    "        z1 = wu1_sb_comp_dense.dot(x) + bu1_sb_comp_dense\n",
    "        a1 = z1 * sigmoid_np(z1)\n",
    "        y = wu2_sb_comp_dense.dot(a1)  \n",
    "        return y\n",
    "\n",
    "    def decoder_u_sb_np_forward_backwardT(x):\n",
    "        z1 = wu1_sb_comp_dense.dot(x) + bu1_sb_comp_dense\n",
    "        sigma = sigmoid_np(z1)\n",
    "        a1 = z1 * sigma\n",
    "        y = wu2_sb_comp_dense.dot(a1) \n",
    "\n",
    "        dout = wu1_sb_comp_denseT\n",
    "        dout = (sigma+a1*(1-sigma))*dout\n",
    "        dydxT = dout.dot(wu2_sb_comp_denseT)\n",
    "        return y,dydxT\n",
    "\n",
    "    def decoder_u_sb_sp_forward(x):\n",
    "        z1 = wu1_sb_comp_dense.dot(x) + bu1_sb_comp_dense\n",
    "        a1 = z1 * sigmoid_np(z1)\n",
    "        y = sp.csr_matrix.dot(wu2_sb_comp_sp,a1)\n",
    "        return y\n",
    "\n",
    "    def decoder_u_sb_sp_forward_backwardT(x):\n",
    "        z1 = wu1_sb_comp_dense.dot(x) + bu1_sb_comp_dense\n",
    "        sigma = sigmoid_np(z1)\n",
    "        a1 = z1 * sigma\n",
    "        y = sp.csr_matrix.dot(wu2_sb_comp_sp,a1)\n",
    "\n",
    "        dout = wu1_sb_comp_denseT\n",
    "        dout = (sigma+a1*(1-sigma))*dout\n",
    "        dydxT = sp.csr_matrix.dot(dout,wu2_sb_comp_spT)\n",
    "        return y,dydxT\n",
    "\n",
    "    for jj in range(len(FOM_parameters)):\n",
    "        FOM_parameter=FOM_parameters[jj]\n",
    "        print(\"Param is {}\".format(FOM_parameter))\n",
    "        \n",
    "        # Load FOM solution\n",
    "        ex = np.load('./diffusion_data/ex16_interp_{}.npz'.format(FOM_parameter), allow_pickle = True)\n",
    "        ex = ex.f.arr_0\n",
    "        u_full = ex.reshape(nt+1,-1).astype('float32')\n",
    "\n",
    "        # take measurments\n",
    "        um = u_full[:,msmt_idx]\n",
    "\n",
    "        # Initial condition\n",
    "        u0=u_full[0]\n",
    "        u_hat0=encoder_u_np_forward(u0.astype('float32')-u_ref)\n",
    "\n",
    "        # gappyAE\n",
    "        t_start_gappyAE=time.time()\n",
    "\n",
    "        # solution\n",
    "        u_reduced=np.zeros((nt+1,latent_dim))\n",
    "        u_gappyAE=np.zeros((nt+1,ny*nx))\n",
    "\n",
    "        # IC\n",
    "        u_reduced[0]=np.copy(u_hat0)\n",
    "        u_gappyAE[0]=np.copy(u0)\n",
    "\n",
    "        for k in range(nt):\n",
    "            print(\"\")\n",
    "            print(k,\"th time step:\")\n",
    "\n",
    "            u_hatw=np.copy(u_reduced[k])\n",
    "\n",
    "            umw,Jg_umT=decoder_u_sb_sp_forward_backwardT(u_hatw)\n",
    "\n",
    "            umw += u_ref[msmt_idx]\n",
    "\n",
    "            Jg_um_pinv=np.linalg.pinv(Jg_umT.T)\n",
    "\n",
    "            r_um_hat = um[k+1]-umw\n",
    "\n",
    "            res = np.linalg.norm(Jg_umT.dot(r_um_hat))\n",
    "            res_hist=[res]\n",
    "            for itr in range(maxitr):\n",
    "                du_hatw = Jg_um_pinv.dot(r_um_hat)\n",
    "\n",
    "                u_hatw += du_hatw\n",
    "\n",
    "                umw,Jg_umT=decoder_u_sb_sp_forward_backwardT(u_hatw)\n",
    "\n",
    "                umw += u_ref[msmt_idx]\n",
    "\n",
    "                Jg_um_pinv=np.linalg.pinv(Jg_umT.T)\n",
    "\n",
    "                r_um_hat = um[k+1]-umw\n",
    "\n",
    "                res = np.linalg.norm(Jg_umT.dot(r_um_hat))\n",
    "#                 res = np.linalg.norm(r_um_hat)\n",
    "                res_hist.append(res)\n",
    "                print(itr,\"th Newton iteration\", \"res:\", \"{:.8e}\".format(res))\n",
    "\n",
    "        #         if res_hist[-2]<res_hist[-1]:\n",
    "        #             print(\"\\n residual increased after {}th iteration\".format(itr))\n",
    "        #             u_reduced[k+1]=(u_hatw-du_hatw).copy()\n",
    "        #             u_gappyAE[k+1]=u_ref+decoder_u_sp_forward(u_reduced[k+1])\n",
    "        #             break\n",
    "\n",
    "                if res<tol:\n",
    "                    break\n",
    "\n",
    "        #     if res>=tol and res_hist[-2]>=res_hist[-1]:\n",
    "    #         if res>=tol:\n",
    "    #             print(\"\\n non converged after {}th iteration\".format(maxitr)) \n",
    "    #             u_reduced[k+1]=u_hatw.copy()\n",
    "    #             u_gappyAE[k+1]=u_ref+decoder_u_sp_forward(u_reduced[k+1])\n",
    "\n",
    "            u_reduced[k+1]=u_hatw.copy()\n",
    "            u_gappyAE[k+1]=u_ref+decoder_u_sp_forward(u_reduced[k+1])\n",
    "\n",
    "        # elapsed time    \n",
    "        t_elapsed_gappyAE=time.time()-t_start_gappyAE\n",
    "        print('Time elapsed: {} sec'.format(t_elapsed_gappyAE))\n",
    "\n",
    "        # error\n",
    "        u_rel_err_gappyAE=np.linalg.norm(u_full-u_gappyAE,ord=2,axis=1)\\\n",
    "                         /np.linalg.norm(u_full,ord=2,axis=1)*100\n",
    "        u_avg_rel_err=np.sqrt(np.sum(np.linalg.norm(u_full-u_gappyAE,ord=2,axis=1)**2))\\\n",
    "                     /np.sqrt(np.sum(np.linalg.norm(u_full,ord=2,axis=1)**2))*100\n",
    "        print(\"average relative error of u: {}%\".format(u_avg_rel_err))\n",
    "        print(\"maximum relative error of u: {}%\".format(np.max(u_rel_err_gappyAE)))\n",
    "        print()\n",
    "\n",
    "        # save result\n",
    "        solution[ii,jj]=u_gappyAE\n",
    "        reduced[ii,jj,:,:f]=u_reduced\n",
    "        avg_rel_err[ii,jj]=u_avg_rel_err\n",
    "        rel_err[ii,jj]=u_rel_err_gappyAE\n",
    "        elapsed_time[ii,jj]=t_elapsed_gappyAE\n",
    "    \n",
    "results={'solution':solution,'reduced':reduced,'avg_rel_err':avg_rel_err,'rel_err':rel_err,'elapsed_time':elapsed_time}\n",
    "with open(file=file_path_gappy_LHS_result, mode='wb') as ff:\n",
    "    pickle.dump(results, ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file=file_path_gappy_LHS_result, mode='rb') as ff:\n",
    "#     results=pickle.load(ff)    \n",
    "\n",
    "idx=[0,1,2,3]\n",
    "\n",
    "# figure avg.rel.err vs params\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in idx:  \n",
    "    plt.plot(FOM_parameters,results['avg_rel_err'][i])\n",
    "#     plt.scatter(FOM_parameters[p_inter:-p_inter:p_inter],results['avg_rel_err'][i][p_inter:-p_inter:p_inter], color = 'blue')\n",
    "plt.xlabel('FOM parameter')\n",
    "plt.ylabel('Avg. Rel. Err.')\n",
    "plt.legend([\"Latent Space Dim. \"+str(f) for f in f_list[idx]])\n",
    "\n",
    "ax=plt.gca()\n",
    "ax.xaxis.set_major_locator(IndexLocator(p_inter,0))\n",
    "ax.xaxis.set_minor_locator(IndexLocator(p_inter,p_inter))\n",
    "ax.tick_params(axis='x',which='minor',labelcolor='blue',labelsize=20)\n",
    "plt.title('Avg. Rel. Err. vs Parameters')\n",
    "# plt.savefig(\"./diffusion_result/ex16_AE_inner_LHS_seed_{}_avg_rel_err_seed_{}.png\".format(LHS_seed,seed))\n",
    "\n",
    "# figure rel.err vs data points\n",
    "plt.figure(figsize=(10,5)) \n",
    "for i in idx:  \n",
    "    plt.plot(FOM_parameters,results['rel_err'][i].max(axis=1))\n",
    "#     plt.scatter(FOM_parameters[p_inter:-p_inter:p_inter],results['rel_err'][i].max(axis=1)[p_inter:-p_inter:p_inter], color = 'blue')\n",
    "plt.xlabel('FOM parameter')\n",
    "plt.ylabel('Max. Rel. Err.')\n",
    "plt.legend([\"Latent Space Dim. \"+str(f) for f in f_list[idx]])\n",
    "plt.title('Max. Rel. Err. vs Parameters')\n",
    "# plt.savefig(\"./diffusion_result/ex16_AE_inner_LHS_seed_{}_max_rel_err_seed_{}.png\".format(LHS_seed,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with open(file=file_path_gappy_LHS_result, mode='rb') as ff:\n",
    "#     results=pickle.load(ff)    \n",
    "\n",
    "idx = [3]\n",
    "\n",
    "# figure avg.rel.err vs params\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in idx:  \n",
    "    plt.plot(FOM_parameters,results['avg_rel_err'][i])\n",
    "#     plt.scatter(FOM_parameters[p_inter:-p_inter:p_inter],results['avg_rel_err'][i][p_inter:-p_inter:p_inter], color = 'blue')\n",
    "plt.xlabel('FOM parameter')\n",
    "plt.ylabel('Avg. Rel. Err.')\n",
    "plt.legend([\"Latent Space Dim. \"+str(f) for f in f_list[idx]])\n",
    "\n",
    "ax=plt.gca()\n",
    "ax.xaxis.set_major_locator(IndexLocator(p_inter,0))\n",
    "ax.xaxis.set_minor_locator(IndexLocator(p_inter,p_inter))\n",
    "ax.tick_params(axis='x',which='minor',labelcolor='blue',labelsize=20)\n",
    "plt.title('Avg. Rel. Err. vs Parameters')\n",
    "plt.show()\n",
    "\n",
    "# figure rel.err vs data points\n",
    "plt.figure(figsize=(10,5)) \n",
    "for i in idx:  \n",
    "    plt.plot(FOM_parameters,results['rel_err'][i].max(axis=1))\n",
    "#     plt.scatter(FOM_parameters[p_inter:-p_inter:p_inter],results['rel_err'][i].max(axis=1)[p_inter:-p_inter:p_inter], color = 'blue')\n",
    "plt.xlabel('FOM parameter')\n",
    "plt.ylabel('Max. Rel. Err.')\n",
    "plt.legend([\"Latent Space Dim. \"+str(f) for f in f_list[idx]])\n",
    "plt.title('Max. Rel. Err. vs Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_list)\n",
    "print(FOM_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure rel.err vs at given param and POD basis\n",
    "i=3; j=-1        \n",
    "f=f_list[i]\n",
    "param=FOM_parameters[j]\n",
    "\n",
    "u_gappyAE=results['solution'][i,j]\n",
    "\n",
    "ex = np.load('./diffusion_data/ex16_interp_{}.npz'.format(param), allow_pickle = True)\n",
    "ex = ex.f.arr_0\n",
    "u_full = ex.reshape(nt+1,-1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(1,nt+1),results['rel_err'][i,j,1:].flatten())\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Rel. Err.')\n",
    "plt.title(\"Latent Dim: {}, Param: {}\".format(f,param))\n",
    "plt.show()\n",
    "\n",
    "# error\n",
    "u_rel_err_gappyAE=np.linalg.norm(u_full-u_gappyAE,ord=2,axis=1)\\\n",
    "                 /np.linalg.norm(u_full,ord=2,axis=1)*100\n",
    "u_avg_rel_err=np.sqrt(np.sum(np.linalg.norm(u_full-u_gappyAE,ord=2,axis=1)**2))\\\n",
    "             /np.sqrt(np.sum(np.linalg.norm(u_full,ord=2,axis=1)**2))*100\n",
    "print(\"average relative error of u: {}%\".format(u_avg_rel_err))\n",
    "print()\n",
    "print(\"maximum relative error of u: {}%\".format(np.max(u_rel_err_gappyAE)))\n",
    "    \n",
    "# plot original data\n",
    "vmin=0; vmax=1\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(35,7),layout='constrained')\n",
    "for i in range(len(axes)):\n",
    "    ax=axes[i]\n",
    "    pcm = ax.pcolor(x.reshape(ny,nx), y.reshape(ny,nx), u_gappyAE[int(nt/4)*i].reshape(ny,nx),vmin=vmin,vmax=vmax)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlabel('x',fontsize=20)\n",
    "    ax.set_ylabel('y',fontsize=20)\n",
    "    ax.set_title('Gappy AE @ t={}'.format(int(nt/4)*i*dt),fontsize=20)\n",
    "\n",
    "fig.colorbar(pcm, ax=axes.tolist(),shrink=0.8)\n",
    "# plt.savefig(\"./diffusion_result/ex16_AE_{}_inner_LHS_seed_{}_SOL_seed_{}.png\".format(f,LHS_seed,seed))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(35,7),layout='constrained')\n",
    "for i in range(len(axes)):\n",
    "    ax=axes[i]\n",
    "    pcm = ax.pcolor(x.reshape(ny,nx), y.reshape(ny,nx), u_full[int(nt/4)*i].reshape(ny,nx),vmin=vmin,vmax=vmax)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlabel('x',fontsize=20)\n",
    "    ax.set_ylabel('y',fontsize=20)\n",
    "    ax.set_title('Ground Truth @ t={}'.format(int(nt/4)*i*dt),fontsize=20)\n",
    "\n",
    "fig.colorbar(pcm, ax=axes.tolist(),shrink=0.8)\n",
    "# plt.savefig(\"./diffusion_result/ex16_ground_truth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3; j=-1\n",
    "f=f_list[i]; param=FOM_parameters[j]\n",
    "print(\"f={}\".format(f))\n",
    "print(\"param={}\".format(param))\n",
    "plt.plot(results['reduced'][i,j][:,:f])\n",
    "plt.legend(np.arange(f))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
